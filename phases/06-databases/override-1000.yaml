# Database values for Mojaloop Performance Testing
# This file configures MySQL and Kafka with proper node placement

## Global settings to allow bitnamilegacy images
global:
  security:
    allowInsecureImages: true

## Reference: https://github.com/bitnamilegacy/charts/blob/main/bitnamilegacy/kafka/values.yaml
kafka:
  enabled: true
  fullnameOverride: "kafka"

  image:
    registry: docker.io
    repository: bitnamilegacy/kafka
    tag: "3.8.1-debian-12-r0"

  service:
    ports:
      client: 9092
      controller: 9093

  listeners:
    client:
      protocol: PLAINTEXT
    controller:
      protocol: PLAINTEXT
    interbroker:
      protocol: PLAINTEXT

  metrics:
    kafka:
      enabled: false

  controller:
    replicaCount: 1
    persistence:
      enabled: false
    resources:
      requests:
        cpu: "14"
        memory: "28Gi"
      limits:
        cpu: "16"
        memory: "48Gi"    

    nodeSelector:
    # Place Kafka broker and controller on dedicated Kafka node
      workload-class.mojaloop.io/KAFKA-DATA-PLANE: "true"
    # Tolerate the dedicated=kafka taint
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "kafka"
        effect: "NoSchedule"            

    podAnnotations: {}

    overrideConfiguration: |
      ########################
      # Replication / Durability
      ########################
      default.replication.factor=1
      min.insync.replicas=1
      unclean.leader.election.enable=true
      auto.leader.rebalance.enable=true

      ########################
      # Topic Management
      ########################
      auto.create.topics.enable=true
      delete.topic.enable=true
      num.partitions=32                    # Increased from 24

      ########################
      # Performance / Threading
      ########################
      num.network.threads=20               # Increased from 10
      num.io.threads=28                    # Increased from 14
      num.replica.fetchers=1               # Reduced since no replication needed
      background.threads=4

      ########################
      # Socket Buffers
      ########################
      socket.send.buffer.bytes=10485760    # 10MB (from 1MB)
      socket.receive.buffer.bytes=10485760 # 10MB (from 1MB)
      socket.request.max.bytes=52428800    # 50MB (from 100MB)
      message.max.bytes=10485760           # 10MB max message

      ########################
      # Log Configuration
      ########################
      log.dirs=/tmp/kafka-logs
      log.segment.bytes=268435456          # 256MB (from 128MB)
      log.flush.interval.messages=50000    # Increased from 25000
      log.flush.interval.ms=100            # Faster flush for low latency
      log.retention.hours=1
      log.retention.bytes=2147483648       # 2GB (from 512MB)
      log.cleanup.policy=delete
      log.cleaner.enable=false

      ########################
      # Zookeeper / Controller Settings
      ########################
      controlled.shutdown.enable=true
      offsets.topic.replication.factor=1
      transaction.state.log.replication.factor=1
      transaction.state.log.min.isr=1

      ########################
      # Request Handling / Queues
      ########################
      queued.max.requests=5000             # Increased from 800
      num.recovery.threads.per.data.dir=1

      ########################
      # Replication Performance
      ########################
      replica.fetch.min.bytes=1
      replica.fetch.max.bytes=10485760     # 10MB (from 1MB)
      replica.fetch.wait.max.ms=500        # Increased from 300
      fetch.max.bytes=104857600            # 100MB (from 50MB)

      ########################
      # Load Testing Tweaks
      ########################
      group.initial.rebalance.delay.ms=0
      producer.purgatory.purge.interval.requests=500    # More aggressive
      consumer.purgatory.purge.interval.requests=500    # More aggressive
      compression.type=producer             # Use producer LZ4 compression

    extraEnvVars:
      - name: KAFKA_HEAP_OPTS
        value: "-Xms28g -Xmx28g"  # Optimized for 64gig  memory
      - name: KAFKA_JVM_PERFORMANCE_OPTS
        value: "-server -XX:+UseG1GC -XX:MaxGCPauseMillis=15 -XX:InitiatingHeapOccupancyPercent=30 -XX:+ExplicitGCInvokesConcurrent -XX:+ParallelRefProcEnabled -Djava.awt.headless=true"
      - name: KAFKA_NUM_NETWORK_THREADS
        value: "20"                # Updated to match override
      - name: KAFKA_NUM_IO_THREADS
        value: "28"                # Updated to match override
      - name: KAFKA_SOCKET_SEND_BUFFER_BYTES
        value: "10485760"
      - name: KAFKA_SOCKET_RECEIVE_BUFFER_BYTES
        value: "10485760"
      - name: KAFKA_SOCKET_REQUEST_MAX_BYTES
        value: "52428800"
      - name: KAFKA_LOG_FLUSH_INTERVAL_MESSAGES
        value: "50000"             # Updated to match override
      - name: KAFKA_LOG_FLUSH_INTERVAL_MS
        value: "100"               # Updated to match override
      - name: KAFKA_LOG_RETENTION_MS
        value: "3600000"
      - name: KAFKA_LOG_SEGMENT_BYTES
        value: "268435456"         # Updated to match override
      - name: KAFKA_DEFAULT_REPLICATION_FACTOR
        value: "1"
      - name: KAFKA_MIN_INSYNC_REPLICAS
        value: "1"
      - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
        value: "1"
      - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
        value: "1"
      - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
        value: "1"
      - name: KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE
        value: "true"
      - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
        value: "true"
      - name: KAFKA_NUM_PARTITIONS
        value: "32"                # Updated to match override
      - name: KAFKA_LOG_CLEANER_ENABLE
        value: "false"
      - name: KAFKA_MESSAGE_MAX_BYTES
        value: "10485760"
      - name: KAFKA_FETCH_MAX_BYTES
        value: "104857600"
      - name: KAFKA_COMPRESSION_TYPE
        value: "producer"
      - name: KAFKA_REPLICA_FETCH_MAX_BYTES
        value: "10485760"          # Added for consistency
      - name: KAFKA_QUEUED_MAX_REQUESTS
        value: "5000"              # Added for consistency
      - name: KAFKA_CFG_PROCESS_ROLES
        value: "controller,broker"
      - name: KAFKA_CFG_CONTROLLER_LISTENER_NAMES
        value: "CONTROLLER"
      - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
        value: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
      - name: KAFKA_CFG_CONTROLLER_QUORUM_VOTERS
        value: "1@localhost:9093"        

  zookeeper:
    enabled: false

  provisioning:
    enabled: true
    waitForKafka: true
    persistence:
      enabled: false
    
    topics:
      # Heavy DB workload - fewer partitions due to DB bottleneck
      - name: topic-transfer-prepare
        partitions: 12
        replicationFactor: 1
      - name: topic-transfer-fulfil
        partitions: 12
        replicationFactor: 1

      # Light HTTP workload - more partitions for parallelism
      - name: topic-quotes-post
        partitions: 12
        replicationFactor: 1
      - name: topic-quotes-put
        partitions: 12
        replicationFactor: 1

      # Batched heavy DB workload - optimized for batch processing
      - name: topic-transfer-position-batch
        partitions: 8
        replicationFactor: 1

      # Light HTTP workload with 2x volume
      - name: topic-notification-event
        partitions: 18
        replicationFactor: 1

      # Low throughput topics - single partition
      - name: topic-transfer-position
        partitions: 1
        replicationFactor: 1
      - name: topic-transfer-get
        partitions: 1
        replicationFactor: 1
      - name: topic-admin-transfer
        partitions: 1
        replicationFactor: 1
      - name: topic-quotes-get
        partitions: 1
        replicationFactor: 1
      - name: topic-bulkquotes-post
        partitions: 1
        replicationFactor: 1
      - name: topic-bulkquotes-put
        partitions: 1
        replicationFactor: 1
      - name: topic-bulkquotes-get
        partitions: 1
        replicationFactor: 1
      - name: topic-bulk-prepare
        partitions: 1
        replicationFactor: 1
      - name: topic-bulk-fulfil
        partitions: 1
        replicationFactor: 1
      - name: topic-bulk-processing
        partitions: 1
        replicationFactor: 1
      - name: topic-bulk-get
        partitions: 1
        replicationFactor: 1
      - name: topic-fx-quotes-post
        partitions: 1
        replicationFactor: 1
      - name: topic-fx-quotes-put
        partitions: 1
        replicationFactor: 1
      - name: topic-fx-quotes-get
        partitions: 1
        replicationFactor: 1
## Reference: https://github.com/bitnamilegacy/charts/blob/main/bitnamilegacy/mysql/values.yaml
mysql:
  enabled: true

  # Override image to use current available version
  image:
    registry: docker.io
    repository: bitnamilegacy/mysql
    tag: "8.0.40-debian-12-r3"

  tls:
    enabled: false

  fullnameOverride: "mysqldb"

  auth:
    rootPassword: "db_password"
    createDatabase: true
    database: mldb
    username: "mluser"
    password: 'ml_password'
    replicationUser: replicator
    replicationPassword: ""
    existingSecret: ""
    usePasswordFiles: false
    customPasswordFiles: {}

  # MySQL metrics configuration
  metrics:
    enabled: false
    # Override metrics exporter image
    image:
      registry: docker.io
      repository: bitnamilegacy/mysqld-exporter
      tag: "0.15.1-debian-12-r9"
    # Service configuration for metrics
    service:
      type: ClusterIP
      port: 9104
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9104"
        prometheus.io/path: "/metrics"
    # Resources for the metrics exporter
    resources:
      limits:
        memory: 256Mi
      requests:
        memory: 128Mi
        cpu: 100m

  ## MySQL Primary parameters
  primary:
    persistence:
      enabled: false
      size: 50Gi
    # OPTIMIZED RESOURCES - FULL NODE UTILIZATION
    resources:
      limits:
        cpu: '16'              # Use all 16 CPUs
        ephemeral-storage: 50Gi # Increased for temp tables
        memory: 56Gi           # 56GB for MySQL, 8GB for OS
      requests:
        cpu: '14'              # Guaranteed all CPUs
        ephemeral-storage: 50Gi
        memory: 54Gi           # Guaranteed memory
    # Pod annotations for primary
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9104"
      prometheus.io/path: "/metrics"

    # Place MySQL on dedicated MySQL nodes
    # Using affinity to allow placement on either ALS or Central Ledger nodes
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: workload-class.mojaloop.io/RDBMS-ALS-LIVE
              operator: In
              values:
              - "true"
          - matchExpressions:
            - key: workload-class.mojaloop.io/RDBMS-CENTRAL-LEDGER-LIVE
              operator: In
              values:
              - "true"

    # Tolerate the dedicated=mysql taint
    tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "mysql"
        effect: "NoSchedule"

    extraEnvVars:
      - name: ACCOUNT_LOOKUP_DATABASE
        value: "account_lookup"
      - name: ACCOUNT_LOOKUP_USER
        value: "account_lookup"
      - name: CENTRAL_LEDGER_DATABASE
        value: "central_ledger"
      - name: CENTRAL_LEDGER_USER
        value: "central_ledger"
      - name: CONTENT_ORACLE_DATABASE
        value: "consent_oracle"
      - name: CONTENT_ORACLE_USER
        value: "consent_oracle"
      - name: AUTH_SVC_DATABASE
        value: "auth_svc"
      - name: AUTH_SVC_USER
        value: "auth_svc"
      - name: MSISDN_ORACLE_DATABASE
        value: "oracle_msisdn"
      - name: MSISDN_ORACLE_USER
        value: "oracle_msisdn"
  ## extraFlags: "--max-connect-errors=1000 --max_connections=155"
    ##

    ## Critical Performance Flags
    ## Durability vs Performance (Load Testing Focus)
    # --innodb_flush_log_at_trx_commit=2  # Faster commits (risk of 1s data loss). For Production change it to 1
    # --sync_binlog=0                     # Disable sync binlog for performance
    # --log_bin=0                         # Disable binary logging

    # ## I/O Optimization
    # --innodb_flush_method=O_DIRECT      # Bypass OS cache for InnoDB
    # --innodb_io_capacity=2000           # Higher IOPS for SSDs
    # --innodb_io_capacity_max=4000       # Maximum burst IOPS
    # --innodb_read_io_threads=8          # Match CPU cores
    # --innodb_write_io_threads=8         # Match CPU cores

    # ## Connection & Thread Management
    # --max_connections=2000              # High for load testing
    # --thread_cache_size=100             # Reuse threads
    # --innodb_thread_concurrency=0       # Unlimited concurrency

    # ## Cache & Buffer Optimization
    # --table_open_cache=4000             # More table handles
    # --table_definition_cache=4000       # More table definitions
    # --tmp_table_size=256M               # Larger temp tables
    # --max_heap_table_size=256M          # Larger memory tables

    extraFlags: |
      --max_connections=5000
      --innodb_buffer_pool_size=40G
      --innodb_log_file_size=4G
      --innodb_log_buffer_size=256M
      --innodb_flush_log_at_trx_commit=2
      --sync_binlog=0
      --innodb_flush_method=O_DIRECT
      --innodb_io_capacity=2000
      --innodb_io_capacity_max=4000
      --innodb_read_io_threads=8
      --innodb_write_io_threads=8
      --innodb_thread_concurrency=0
      --thread_cache_size=100
      --table_open_cache=4000
      --table_definition_cache=4000
      --max_allowed_packet=256M
      --tmp_table_size=256M
      --max_heap_table_size=256M
      --sort_buffer_size=4M
      --read_buffer_size=2M
      --read_rnd_buffer_size=1M
      --join_buffer_size=4M
      --key_buffer_size=64M
      --binlog_format=ROW
      --log_bin=0
      --slow_query_log=0
      --performance_schema=OFF
      --skip_name_resolve
      --default_authentication_plugin=mysql_native_password    
  ## Initialize databases
  initdbScripts:
    accountLookupInit.sh: |
      #!/bin/bash
      set -e
      DB_NAME=$ACCOUNT_LOOKUP_DATABASE
      DB_USER=$ACCOUNT_LOOKUP_USER
      DB_PASS=$MYSQL_PASSWORD
      echo "******* Creating '$DB_NAME' DB with user '$DB_USER' *******"
      mysql -u root -p$MYSQL_ROOT_PASSWORD -e \
        "DROP DATABASE IF EXISTS $DB_NAME;
        CREATE DATABASE $DB_NAME;
        DROP USER IF EXISTS $DB_USER@'%';
        CREATE USER '$DB_USER'@'%' IDENTIFIED BY '$DB_PASS';
        GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'%';
        FLUSH PRIVILEGES;"
      echo "******* Database '$DB_NAME' config complete *******"

    centralLedgerInit.sh: |
      #!/bin/bash
      set -e
      DB_NAME=$CENTRAL_LEDGER_DATABASE
      DB_USER=$CENTRAL_LEDGER_USER
      DB_PASS=$MYSQL_PASSWORD
      echo "******* Creating '$DB_NAME' DB with user '$DB_USER' *******"
      mysql -u root -p$MYSQL_ROOT_PASSWORD -e \
        "DROP DATABASE IF EXISTS $DB_NAME;
        CREATE DATABASE $DB_NAME;
        DROP USER IF EXISTS $DB_USER@'%';
        CREATE USER '$DB_USER'@'%' IDENTIFIED BY '$DB_PASS';
        GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'%';
        FLUSH PRIVILEGES;"
      echo "******* Database '$DB_NAME' config complete *******"

    consentOracleInit.sh: |
      #!/bin/bash
      set -e
      DB_NAME=$CONTENT_ORACLE_DATABASE
      DB_USER=$CONTENT_ORACLE_USER
      DB_PASS=$MYSQL_PASSWORD
      echo "******* Creating '$DB_NAME' DB with user '$DB_USER' *******"
      mysql -u root -p$MYSQL_ROOT_PASSWORD -e \
        "DROP DATABASE IF EXISTS $DB_NAME;
        CREATE DATABASE $DB_NAME;
        DROP USER IF EXISTS $DB_USER@'%';
        CREATE USER '$DB_USER'@'%' IDENTIFIED BY '$DB_PASS';
        GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'%';
        FLUSH PRIVILEGES;"
      echo "******* Database '$DB_NAME' config complete *******"

    msisdnOracleInit.sh: |
      #!/bin/bash
      set -e
      DB_NAME=$MSISDN_ORACLE_DATABASE
      DB_USER=$MSISDN_ORACLE_USER
      DB_PASS=$MYSQL_PASSWORD
      echo "******* Creating '$DB_NAME' DB with user '$DB_USER' *******"
      mysql -u root -p$MYSQL_ROOT_PASSWORD -e \
        "DROP DATABASE IF EXISTS $DB_NAME;
        CREATE DATABASE $DB_NAME;
        DROP USER IF EXISTS $DB_USER@'%';
        CREATE USER '$DB_USER'@'%' IDENTIFIED BY '$DB_PASS';
        GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'%';
        FLUSH PRIVILEGES;"
      echo "******* Database '$DB_NAME' config complete *******"

    authSvcInit.sh: |-
      #!/bin/bash
      set -e
      DB_NAME=$AUTH_SVC_DATABASE
      DB_USER=$AUTH_SVC_USER
      DB_PASS=$MYSQL_PASSWORD
      echo "******* Creating '$DB_NAME' DB with user '$DB_USER' *******"
      mysql -u root -p$MYSQL_ROOT_PASSWORD -e \
        "DROP DATABASE IF EXISTS $DB_NAME;
        CREATE DATABASE $DB_NAME;
        DROP USER IF EXISTS $DB_USER@'%';
        CREATE USER '$DB_USER'@'%' IDENTIFIED BY '$DB_PASS';
        GRANT ALL PRIVILEGES ON $DB_NAME.* TO '$DB_USER'@'%';
        FLUSH PRIVILEGES;"
      echo "******* Database '$DB_NAME' config complete *******"

## MongoDB Configuration with Metrics
cl-mongodb:
  enabled: true
  fullnameOverride: "cl-mongodb"

  # Override image to use current available version
  image:
    registry: docker.io
    repository: bitnamilegacy/mongodb
    tag: "7.0.15-debian-12-r0"

  auth:
    enabled: true
    rootUser: root
    rootPassword: "adminpass"
    usernames:
      - 'mojaloop'
    passwords:
      - 'password'
    databases:
      - 'mlos'

  # MongoDB metrics configuration
  metrics:
    enabled: true
    port: 9216
    # Override metrics exporter image
    image:
      registry: docker.io
      repository: bitnamilegacy/mongodb-exporter
      tag: "0.41.2-debian-12-r0"
    service:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9216"
        prometheus.io/path: "/metrics"
    resources:
      limits:
        memory: 128Mi
      requests:
        memory: 64Mi
        cpu: 50m

  # Pod annotations
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9216"
    prometheus.io/path: "/metrics"

  persistence:
    enabled: false

## TTK MongoDB with Metrics
ttk-mongodb:
  enabled: true
  fullnameOverride: "ttk-mongodb"

  # Override image to use current available version
  image:
    registry: docker.io
    repository: bitnamilegacy/mongodb
    tag: "7.0.15-debian-12-r0"

  auth:
    enabled: true
    rootUser: root
    rootPassword: "adminpass"
    usernames:
      - 'ttk'
    passwords:
      - 'ttk'
    databases:
      - 'ttk'

  # MongoDB metrics configuration
  metrics:
    enabled: true
    port: 9216
    # Override metrics exporter image
    image:
      registry: docker.io
      repository: bitnamilegacy/mongodb-exporter
      tag: "0.41.2-debian-12-r0"
    service:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9216"
        prometheus.io/path: "/metrics"
    resources:
      limits:
        memory: 128Mi
      requests:
        memory: 64Mi
        cpu: 50m

  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9216"
    prometheus.io/path: "/metrics"

  persistence:
    enabled: false

## Redis Configuration with Metrics
ttksims-redis:
  enabled: true
  architecture: standalone
  fullnameOverride: ttksims-redis

  # Override image to use current available version
  image:
    registry: docker.io
    repository: bitnamilegacy/redis
    tag: "7.4.1-debian-12-r0"

  auth:
    enabled: false

  # Redis metrics configuration
  metrics:
    enabled: false
    port: 9121
    # Override metrics exporter image
    image:
      registry: docker.io
      repository: bitnamilegacy/redis-exporter
      tag: "1.66.0-debian-12-r0"
    service:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9121"
        prometheus.io/path: "/metrics"
    resources:
      limits:
        memory: 128Mi
      requests:
        memory: 64Mi
        cpu: 50m

  master:
    persistence:
      enabled: false

    # Pod annotations
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9121"
      prometheus.io/path: "/metrics"

## Auth Service Redis with Metrics
auth-svc-redis:
  enabled: true
  architecture: standalone
  fullnameOverride: auth-svc-redis

  # Override image to use current available version
  image:
    registry: docker.io
    repository: bitnamilegacy/redis
    tag: "7.4.1-debian-12-r0"

  auth:
    enabled: false

  # Redis metrics configuration
  metrics:
    enabled: false
    port: 9121
    # Override metrics exporter image
    image:
      registry: docker.io
      repository: bitnamilegacy/redis-exporter
      tag: "1.66.0-debian-12-r0"
    service:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9121"
        prometheus.io/path: "/metrics"
    resources:
      limits:
        memory: 128Mi
      requests:
        memory: 64Mi
        cpu: 50m

  master:
    persistence:
      enabled: false

    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9121"
      prometheus.io/path: "/metrics"

## Proxy Cache Redis Cluster with Metrics
proxy-cache-redis:
  enabled: true
  usePassword: false
  fullnameOverride: proxy-cache-redis
  clusterDomain: cluster.local

  # Override image to use current available version
  image:
    registry: docker.io
    repository: bitnamilegacy/redis-cluster
    tag: "8.2.1-debian-12-r0"

  persistence:
    enabled: false

  cluster:
    init: true
    nodes: 6
    replicas: 1

  # Redis Cluster metrics configuration
  metrics:
    enabled: false
    port: 9121
    # Override metrics exporter image
    image:
      registry: docker.io
      repository: bitnamilegacy/redis-exporter
      tag: "1.66.0-debian-12-r0"
    service:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9121"
        prometheus.io/path: "/metrics"
    resources:
      limits:
        memory: 128Mi
      requests:
        memory: 64Mi
        cpu: 50m

  # Pod annotations for all cluster nodes
  redis:
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9121"
      prometheus.io/path: "/metrics"